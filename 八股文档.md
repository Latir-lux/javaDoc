# 八股训练营

整理顺序为代码随想录八股训练营题目顺序

## Day1

### Case1

------

#### 题目：介绍一下TCP/IP模型和OSI模型的区别

**答案：**

**1.OSI模型**

OSI模型是国际标准化组织（ISO）制定的一个用于计算机或者通信系统之间互联的标准体系，把计算机网络通信划分为七个不同的层级，每个层级负责特定的功能。每个层级都构建在其下方的层级之上，并且为其上方的层级提供服务。
七层从下到上分别为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。

**2.OSI模型和TCP/IP模型关系**

OSI模型发布时间比TCP/IP模型早，并且理论上OSI模型更全面，但是实际上TCP/IP模型更加实用，所以目前大多数开发场景都基于TCP/IP模型。

**3.TCP/IP模型**

TCP/IP模型分为四层，下面从上到下进行介绍。

**应用层：**
最上层是应用层，这一层与OSI模型的应用层、表示层和会话层相似，提供直接与用户程序交互的接口，比如电子邮件（SMTP）、网页浏览（HTTP）、文件传输（FTP）等。

各种计算机系统的应用软件都是在应用层实现的，两个不同设备的应用需要通信时，应用层就把数据传给下一层，并不关心数据是如何传输的。

（回答时候去掉：应用层工作在操作系统的用户态，传输层及一下工作在内核态。）

**传输层：**
应用层下面是传输层，该层对应OSI模型的传输层，负责在端到端的数据传输时提供传输服务。

主要有两个传输协议，TCP和UDP。TCP提供可靠的数据传输，确保了数据的正确性和完整性。UDP则是无连接的、不可靠的，实时性更好，效率更高，适用于不要求可靠性的传输，比如实时音频和视频流。

**网络层：**
传输层下面是网络层，该层对应OSI模型的网络层。传输层听起来像是负责把数据从一个设备传输到另一个设备，事实上这部分是由网络层负责的，传输层的功能是服务好应用层，也就是打包和接收数据。

网络层的常用协议是IP协议，主要作用是寻址和路由，用IP地址标识源主机和目标主机，用路由来选择最佳路径传输数据。

**网络接口层：**
网络层下面是网络接口层，该层对应OSI模型的数据链路层和物理层。

网络层只负责网络层级的传输，网络接口层则负责这个层级之下物理传输媒介的传输，比如以太网、WiFi等。这个层级使用MAC地址标识网络上的设备，所以网络接口层包含对MAC地址的管理，也有错误检测和纠错功能。

详细内容参考：[2.1 TCP/IP 网络模型有哪几层？ | 小林coding](https://xiaolincoding.com/network/1_base/tcp_ip_model.html#应用层)

### Case2

------

#### 题目：从输入URL到页面展示到底发生了什么？

**答案：**

**第一步**是浏览器对URL进行解析，生成发送给Web服务器的请求信息。

**第二步**是查询得到服务器域名对应的IP地址。查询的顺序是浏览器缓存，操作系统缓存，host文件，路由器缓存，本地DNS服务器。这部分都是客户端在访问，之后如果本地DNS服务器没有IP信息，本地DNS服务器会依次访问根DNS服务器，顶级DNS服务器，权威DNS服务器，最后从权威DNS服务器得到IP地址返回给客户端。

**第三步**，有了IP地址之后，浏览器与服务器IP三次握手建立TCP连接。

**第四步**，将第一步得到的http报文依次包上TCP头部、IP头部、MAC头部，其中还会包含和该域名相关的Cookie等数据，然后浏览器就会将请求发出。如果是HTTPS的话，还要涉及到HTTPS的加密解密流程。

**第五步**，请求发出之后，会依次经过网卡、交换机、路由器等设备，最终到达目标IP。这个过程中的MAC头部会不断的变化，但是源IP和目的IP一直不会改变。

**第六步**，服务器接收到请求，一层层解析头部，同时判断这个请求是否是发给自己的，如果是发给自己的，根据请求生成响应数据。

**第七步**，TCP四次挥手断开连接，浏览器和服务器IP断开TCP连接。

**第八步**，浏览器解析响应数据并渲染页面。

下面这部分是拓展，考官问了说。

- 浏览器解析响应头。若响应头状态码为301、302，会重定向到新地址；若响应数据类型是字节流类型，一般会将请求提交给下载管理器；若是HTML类型，会进入下一部渲染流程。
- 浏览器解析HTML文件，创建DOM树，解析CSS进行样式计算，然后将CSS和DOM合并，构建渲染树；最后布局和绘制渲染树，完成页面展示。

详细内容参考：[2.2 键入网址到网页显示，期间发生了什么？ | 小林coding](https://xiaolincoding.com/network/1_base/what_happen_url.html)

## Day2

### Case1

#### 题目：HTTP请求报文和响应报文是怎样的，有哪些常见的字段？

**答案**：

HTTP报文分为请求报文和响应报文

**请求报文**主要由**请求行、请求头部、空行和请求数据**四个部分组成。
**请求行**由**请求方法、URI和HTTP协议版本**三个字段组成，每个字段之间用空格隔开，最后一个字段后面跟回车符和换行符。
**请求方法**有以下几种：HTTP1.0定义了GET、POST和HEAD三种方法，HTTP1.1新增了OPTIONS、PUT、PATCH、DELETE、TRACE和CONNECT六种方法。
**请求头部**字段常见的有：

- Accept：客户端能够处理的媒体类型。
- Accept-Encoding：客户端能够解码的内容编码方式，比如gzip。
- Accept-Language：客户端所希望的语言种类，在服务器能够提供一种以上的语言版本时需要。
- Authorization：用于认证的凭证信息，比如token数据。
- Content-Type：请求体的媒体类型。
- Content-Length：请求体的长度。
- Host：客户端要访问的服务器域名。
- User-Agent：包含发出请求的用户信息，客户端类型。
- Cookie：存储在客户端的cookie数据。
- Connection：管理连接的选项，比如keep-alive。
- If-None-Match：资源的ETag值，用于缓存控制。

请求头部之后是**空行**，用于告知服务器请求头部到此为止。
在空行之后是**请求数据**，如果方法字段是GET，那么这一项为空，如果是方法字段是POST，请求数据是要提交的数据，比如我要登录服务器，这部分就会放置username和password。

**响应报文**是服务器向客户端返回的数据格式，用于传达服务器对客户端请求的处理结果和相关数据。主要由**状态行、响应头部、空行和响应正文**四个部分组成。
**状态行**由**协议版本、状态码和原因短语**组成，每个字段由空格隔开，其中原因短语是可选的。最后也跟回车符和换行符。
**响应头部**字段常见的有：

- Allow：服务器支持哪些请求方法。
- Content-Encoding：文档的编码方法。
- Content-Length：响应正文的长度。
- Content-Type：响应正文的媒体类型。
- Date：当前的GMT时间。
- Location：该字段会配合302状态码使用，重定向到一个新的URI地址。
- Server：指定服务器的信息。
- Set-Cookie：设置与页面关联的Cookie。
- Last-Modified：资源最后被修改的日期和时间。
- Expires：响应的过期时间，之后的内容被认为是过时的。
- ETag：响应体的实体标签，用于缓存和条件请求。
- Access-Control-Allow-Origin: 跨源资源共享（CORS）策略，指示哪些域可以访问资源。

响应头部之后也是一个**空行**，用于告知响应头部结束了。

最后是**响应正文**，是服务端实际传输的数据，可以是文本、HTML页面、图片、视频等，也可以是空。

详细内容参考：

[训练营](https://kamacoder.com/training-camp/32)

[3.2.5 HTTP_1.1请求报文格式_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1gg4y1P7Yt/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

[3.2.6 HTTP_1.1响应报文格式_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Sm4y1J7dr/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case2

#### 题目：HTTP有哪些请求方式？

**答案：**

| 序号 | 方法    | 描述                                                         |
| ---- | ------- | ------------------------------------------------------------ |
| 1    | GET     | 请求从服务器获取一个资源                                     |
| 2    | POST    | 向指定资源提交数据进行处理请求，比如提交表单                 |
| 3    | HEAD    | 请求一个与GET请求相同的响应，但是没有响应体，用于检查资源的元数据 |
| 4    | PUT     | 发送数据以更新现有资源，如果资源不存在则创建新的资源         |
| 5    | DELETE  | 删除指定的资源                                               |
| 6    | PATCH   | 对资源进行部分修改，PUT是整个替换，PATCH是修改部分           |
| 7    | OPTIONS | 查询服务器支持的请求方法                                     |
| 8    | TRACE   | 对到目标资源的路径进行环回测试，主要用于诊断                 |
| 9    | CONNECT | 建立一个到服务器的隧道，常用于HTTPS连接                      |

详细内容参考：

[HTTP 请求方法 - HTTP | MDN](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods)

[HTTP 请求方法 | 菜鸟教程](https://www.runoob.com/http/http-methods.html)

### Case3

#### 题目：GET请求和POST请求的区别

**答案：**

按照RFC规范分析，两者主要有以下区别：

- 语义：GET是从服务器获取指定资源，POST是根据请求负荷对指定的资源作出处理。
- 参数：GET参数一般写在URL中，并且只支持ASCII字符，浏览器对URL的长度会有限制。POST携带的数据一般写在报文body中，支持任意格式，理论上没有长度限制。
- 安全性：针对服务器的安全来说，GET属于“只读”类型，不会修改服务器数据，是安全的，POST会修改数据，对服务器不安全。针对数据泄露的安全来说，GET的数据直接暴露在URL中，而POST的数据在HTTP协议下可以通过抓包得到，两者都不太安全。
- 幂等：GET因为是“只读”的，所以他是幂等的，而POST每次提交都可能修改数据或者创建资源，不是幂等的。
- 缓存：GET请求可以被缓存，而POST默认不会被缓存。

详细内容参考：

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#get-与-post)

[GET - HTTP | MDN](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET)

[POST - HTTP | MDN](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/POST)

## Day3

### Case1

#### 题目：HTTP中常见的状态码有哪些？

**答案：**

1xx类状态码是信息响应，属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

2xx类状态码是成功响应，表示服务器**成功**处理了客户端的请求，常用的如下：

- [200 OK] 是最常见的成功状态码，表示一切正常。
- [201 Created] 表示请求成功，并且因为请求创建了一个新的资源，通常是对POST或者PUT请求的响应。
- [204 No Content] 与200基本相同，但响应头没有body数据。
- [206 Partial Content] 应用于HTTP分块下载或断点续传，响应返回的body数据是资源的一部分。

3xx类状态码是重定向消息，表示客户端请求的资源发生了变动，常用如下：

- [301 Moved Permanently] 表示永久重定向，用返回的新URL访问。
- [302 Found] 表示临时重定向，请求的资源还在，暂时用另一个URl访问。
- [304 Not Modified] 表示资源未修改，客户端可以使用缓存文件，用于缓存控制。

4xx类状态码表示客户端发送的报文有误，服务器无法处理，常用如下：

- [400 Bad Request] 表示客户端请求的报文有错误，服务器无法处理。
- [401 Unauthorized] 客户端需要对自身进行身份验证。
- [403 Forbidden] 客户端没有访问资源的权限。401服务器不知道客户端身份，但是403知道。
- [404 Not Found] 服务器找不到请求的资源。在403时，服务器也可以返回404，用于对客户端隐藏资源。

5xx类状态码表示客户端请求报文正确，处理时服务器内部发生错误。

- [500 Internal Server Error] 与400类似，是个笼统的错误码。
- [501 Not Implemented] 服务端不支持客户端的请求方法。
- [502 Bad Gateway] 服务器作为网关自身正常工作，但是自身访问的下一个服务器出错。
- [503 Service Unavailable] 表示服务器没准备好处理请求，可能因维护或者重载而停机。

### Case2

#### 题目：什么是强缓存和协商缓存

**答案：**

对于一些重复性的HTTP请求，比如每次请求得到的数据都一样，可以直接把数据缓存在本地，不必通过网络获取服务器的响应，这样HTTP/1.1的性能可以得到提升。
HTTP的缓存实现的方式分为强制缓存和协商缓存。

**强制缓存：**
浏览器如果判断缓存没过期，不发送请求直接使用浏览器本地缓存就是强制缓存。
强制缓存主要由响应头部中的**Cache-Control和Expires**实现。如果头部同时有这两个字段，Cache-Control的优先级比Expires高。

1. 使用**Expires**的强缓存会在Expires字段中设置一个**强缓存时间**，浏览器判断是否过期的方式是读取**本地时间**与Expires字段的时间进行比较。但是如果本地时间与服务器时间不一致时，就会出问题。而且Expires的刷新时间是一秒，在一秒内资源发生变化也会出现问题。
2. 使用**Cache-Control**的强缓存会在字段中设置**max-age**来告知浏览器指定时间内可以使用缓存。与Expires相比，Expires是相对时间，而max-age是绝对时间，不会出现时间不一致的问题。而且服务器每次收到请求，会重新计算资源可以被缓存使用的剩余时间，解决了Expires的两个问题。

**协商缓存：**

HTTP的状态码中有一个是304，作用是告知浏览器可以使用缓存，这种通过**服务端告知客户端**可以使用缓存的方式是协商缓存，也就是通过协商结果判断是否使用本地缓存。也有两种实现方式。

1. 第一种是用请求头部中的**If-Modified-Since字段**和响应头部中的**Last-Modified字段**实现。

   - 使用方法是**服务器发送资源**时会在Last-Modified字段中存储资源最后修改的时间。
   - 当强制缓存资源过期，客户端**再次请求这个资源**时，请求头部中的If-Modified-Since字段值就是收到资源时Last-Modified字段值。
   - **服务器收到请求**看到有If-Modified-Since字段，比较字段值和被请求资源当前的Last-Modified值，如果已经更新，正常返回资源，没有更新则返回304。

   这种方式的两种缺陷：在**没有修改文件内容**时文件的最后修改时间也可能会改变，比如重命名后改回；另外是文件修改时间记录的**最小单位是秒**，如果在几百毫秒内完成修改，文件修改时间并不会改变。

2. 第二种使用请求头部中的**If-None-Match字段**和响应头部的**ETag字段**实现。ETag是根据文件内容计算得到的唯一哈希值。

   - 使用方法是**服务器提供资源**时将ETag和资源一起发给客户端。
   - 强制缓存资源过期，客户端**再次请求**时，会在If-None-Match字段中携带资源的ETag值。
   - 服务器会**比较请求**中的If-None-Match值和当前资源的ETag值，匹配则资源未发生变化，返回304，如果不匹配正常返回资源。

第一次请求资源时，服务端返回的响应头部如果**同时有ETag和Last-Modified字段**，客户端在下一次请求时，如果**也带上了这两个**信息，那么**ETag的优先级更高**。
最后，协商缓存的两个字段都要配合强制缓存中的**Cache-Control字段**来使用，只有**未能命中强制缓存，才能发起带有协商缓存的请求**。

详细内容参考：

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#http-缓存技术)
[HTTP缓存自述-5分钟了解我的关键历程【前端面试宝典】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1kV4y1K7Rx/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

## Day4

### Case1

#### 题目：HTTP1.0和HTTP1.1的区别

**答案：**

1. **持久连接**：`HTTP/1.0`是短链接，每次请求都要重新建立连接，而一个网页可能需要html、css、js和各种图片文件，请求一个网页会有很多TCP连接断开，并且持久连接要用keep-alive实现，而且不能复用。`HTTP/1.1`默认是长连接的通信方式，也就是持久连接，只要任意一端没有明确提出断开连接，则保持TCP连接状态，减少了重复建立和断开造成的额外开销。

2. **管道化**：`HTTP/1.1`使用持久连接，所以可以使用管道化（不是默认开启），也就是在同一个TCP连接里，客户端可以发起多个请求，只要第一个请求发出去了，**不用等待响应**，就可以发送第二个请求，减少整体的响应时间。但是服务器需要按照**接收请求的顺序发送响应**，如果前面的需求耗时较长，后续的处理会被阻塞。所以HTTP/1.1解决了请求的队头阻塞，但没有解决**响应的队头阻塞**。

3. **缓存控制**：`HTTP/1.0`主要使用If-Modified-Since/Expires来作为缓存判断的标准，`HTTP/1.1`则引入了更多的缓存控制策略，比如ETag/If-None_Match等。

   除了这三点之外`HTTP/1.1`还优化了一些细节的部分。

4. 错误处理：`HTTP/1.1`增加了新的状态码，比如`100 Continue`，用于增强错误处理和请求的中间响应。

5. `Host`头：`HTTP/1.1`新增了`Host`头，允许客户端指定请求的主机，使得一台服务器可以托管多个域名。

6. 局部请求：`HTTP/1.0`中，客户端无法请求资源的一部分，会导致带宽浪费，`HTTP/1.1`在请求头中新增了`range`，允许只请求资源的某个部分，此时返回码是`206（Partial Content）`。

详细内容参考：

[训练营](https://kamacoder.com/training-camp/32)

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#http-1-1-的性能如何)

### Case2

#### 题目：HTTP2.0与HTTP1.1的区别

**答案：**

1. **头部压缩**：`HTTP/2.0`引入了`HPACK`压缩算法，对请求和响应的头部信息进行压缩。具体操作是在客户端和服务器同时维护一张头信息表，所有发送过的字段都会存入这个表，生成一个索引值，之后对同样的字段只发送索引值。
2. **二进制协议**：`HTTP/1.1`采用了纯文本形式，而`HTTP/2.0`全面采用了二进制格式。头信息和数据体都是二进制，统称为帧：头信息帧和数据帧。增加了数据传输效率。
3. **并发传输**：也就是**多路复用**，`HTTP/1.1`是串行的，完成一个事务之后才能处理下一个事务。`HTTP/2.0`则引出了Stream的概念，一个TCP连接包含多个Stream，Stream里可以包含1个或多个Message，Message对应`HTTP/1.1`中的请求或响应，Message里包含一个或者多个Frame，Frame是`HTTP/2.0`的最小单位。针对不同的请求用Stream ID来区分，接收端可以通过Stream ID有序组装HTTP消息，所以`HTTP/2.0`可以并行交错发送多个请求和响应，但同一个Stream里的顺序是严格的，解决了队头阻塞。
4. **服务器推送**：`HTTP/2.0`允许服务器通过Stream主动推送资源给客户端，这样可以减少页面加载时间。其中客户端的Stream ID必须是奇数，服务器的Stream ID必须是偶数。
5. **优先级和依赖**：`HTTP/2.0`允许客户端为请求设置优先级，并表达请求之间的依赖关系，资源加载更加有序。

详细内容参考：

[3.6 HTTP/2 牛逼在哪？ | 小林coding](https://xiaolincoding.com/network/2_http/http2.html#总结)

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#http-2-做了什么优化)

### Case3

#### 题目：HTTP3.0有了解过吗

**答案：**

`HTTP/3.0`是HTTP协议的最新版本，基于QUIC协议，具有以下特点：

1. **无队头阻塞**：`HTTP/2.0`虽然基本消除了队头阻塞，但是因为使用TCP协议，如果丢包会触发TCP重传。QUIC协议也有类似`HTTP/2.0`中Stream和多路复用的概念，也可以在同一条连接上并发传输多个Stream，但是他使用`UDP`协议来传输数据，多个Stream之间没有依赖，一个Stream丢包之后，只会阻塞这个Stream，不影响其他Stream，不存在队头阻塞问题。
2. **0RTT连接建立**：`HTTP/1.1`和`HTTP/2.0`中，TCP和TLS是分层的，一个属于传输层，一个属于表示层，难以合并。而`HTTP/3.0`的QUIC协议内部包含了TLS，所以QUIC的帧会携带TLS的记录。QUIC本身握手过程只需要一个RTT，`TLS/1.3`也只需要一个RTT来完成密钥协商，所以两者合并后第一次连接只需要一个RTT。甚至第二次连接时，数据包和握手信息会一起发送，达到0RTT建立连接。
3. **连接迁移**：基于TCP的协议是通过四元组确定一条TCP连接，四元组中包含源IP和目的IP，在网络切换时，IP地址变化就要断开连接。QUIC协议则通过**连接ID**来标记通信的两个端点，实现了连接迁移。
4. 向前纠错机制：每个数据包除了它本身的内容之外，还包括了部分其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。向前纠错牺牲了每个数据包可以发送数据的上限，但是减少了因为丢包导致的数据重传。
5. 安全性：`HTTP/3.0`默认使用TLS加密，确保了数据传输的安全性。

详细内容参考：

[3.7 HTTP/3 强势来袭 | 小林coding](https://xiaolincoding.com/network/2_http/http3.html#http-3-协议)

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#http-3-做了哪些优化)

## Day5

### Case1

#### 题目：HTTPS和HTTP有哪些区别

**答案：**

HTTPS和HTTP的区别主要有以下四点：

1. `HTTP`是超文本传输协议，信息是明文传输，存在安全风险问题。`HTTPS`则解决了`HTTP`不安全的缺陷，在`TCP`和`HTTP`网络层之间加入了`SSL/TLS`安全协议，使报文可以加密传输。
2. `HTTP`连接建立相对简单，`TCP`三次握手之后便可进行`HTTP`的报文传输。而`HTTPS`在`TCP`三次握手之后，还需进行`SSL/TLS`的握手过程，才可进入加密报文传输。
3. 两者默认的端口号不一样，`HTTP`默认端口号是80，`HTTPS`默认端口号是443。
4. `HTTPS`协议需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

总的来说，两者的主要区别在于安全性和数据加密。

详细内容参考：

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#http-与-https-有哪些区别)

[HTTPS是什么？加密原理和证书。SSL/TLS握手过程_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1KY411x7Jp/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case2

#### 题目：HTTPS的工作原理（HTTPS建立连接的过程）

**答案：**

`HTTPS`主要基于`SSL/TLS`协议，确保数据传输的安全性和完整性，连接建立时，首先建立`TCP`连接，之后建立`SSL/TLS`连接，`SSL/TLS`连接建立过程如下：

1. **密钥交换**：分为两个部分。

   ​	`ClientHello`：首先由客户端向服务器发起加密通信请求，也就是`ClientHello`，其中会包含三个信息：客户端支持的`TLS`协议版本；客户端生成的一个随机数（`Client Random`）；客户端支持的密码套件列表。

   ​	`ServerHello`：服务器收到客户端请求后，向客户端发出响应，也就是`ServerHello`，回应内容主要有以下几点：确认`TLS`协议版本，如果浏览器不支持，关闭加密通信；服务器生成的随机数（`Server Random`）；确认密码套件列表；服务器的数字证书。

2. **证书验证**：客户端收到服务器的响应之后，首先通过CA公钥，确认服务器数字证书的真实性，如果没问题，得到数字证书中服务器的公钥，利用公钥加密报文，向服务器发送以下三个信息：一个被公钥加密的随机数；加密通信算法改变通知，之后的信息会用[会话密钥]进行加密；客户端握手结束通知。

3. **建立安全连接**：证书验证后客户端生成的随机数，会和之前的`Client Random`和`Server Random`一起构建成一个[会话密钥]。最后的随机数会被公钥加密发送给服务器，所以只有服务器和客户端知道[会话密钥]内容，这时就可以实现对称加密。得到密钥之后服务器也会通知客户端，之后使用加密通信，握手阶段结束，握手过程完成之前，客户端与服务端之间的加密都是非对称加密。

4. **完整性校验**：TLS在实现上分为**握手协议**和**记录协议**两层：记录协议负责保护应用程序数据并验证其完整性和来源，比如使用消息认证码来确保数据在传输过程中没有被篡改。

5. **结束链接**：数据传输完成后，通信双方会进行会话密钥的销毁，以确保不会留下安全隐患。

详细内容参考：

[3.1 HTTP 常见面试题 | 小林coding](https://xiaolincoding.com/network/2_http/http_interview.html#https-解决了-http-的哪些问题)

[3.5 HTTPS 如何优化？ | 小林coding](https://xiaolincoding.com/network/2_http/https_optimize.html#分析性能损耗)

[HTTPS是什么？加密原理和证书。SSL/TLS握手过程_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1KY411x7Jp/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case3

#### 题目：TCP和UDP的区别

**答案：**

1. `TCP`是**面向连接**的协议，数据传输前需要三次握手建立连接，数据传输后需要四次挥手断开连接；`UDP`是**无连接**的，不需要建立连接。
2. 因为`TCP`是面向连接的，所以只支持单播，而`UDP`则支持广播、多播和单播。
3. UDP对应用层交下来的报文**不拆分也不合并**，直接套上UDP头，也就是说他是**面向应用报文**的；而TCP是**面向字节流**的，会把应用层交下来的数据包看成一连串的字节流，只保证收到和发出的字节流一致，过程中可能拆分或者合并。
4. TCP提供**可靠**的数据传输，保证数据包的顺序和完整性，可以**检测并重传**丢失或损坏的数据包；UDP则提供无连接不可靠的传输，数据包丢失或者损坏没有错误恢复机制。
5. TCP具有**拥塞控制机制**，可以根据网络状况调整数据传输速率；UDP没有拥塞控制。
6. TCP通过**滑动窗口机制**进行流量控制，避免接收方处理不过来；UDP没有流量控制。
7. TCP具有**复杂的报文头部**，最小20字节，最大60字节；UDP报文头部则是8字节。
8. 由于TCP的连接建立、数据校验和重传机制，其性能开销通常比UDP大；UDP由于简单，性能开销小。
9. 适用场景：TCP适用于需要可靠传输的应用，如网页浏览、文件传输等；UDP适用于对实时性要求高的应用，如语音通话、视频会议等。

详细内容参考：

[计算机网络微课堂第067讲 UDP和TCP的对比（有字幕无背景音乐版）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1JJ411V7Dn/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

## Day6

### Case1

#### 题目：TCP连接如何确保可靠性

**答案：**

`TCP`通过差错控制（校验和、确认应答、重传）、流量控制、拥塞控制等机制，确保了数据传输的可靠性和效率。

1. **序列号**：`TCP`通过序列号来确认数据包的传输顺序，以及检测是否丢包。
2. **校验和**：每个`TCP`首部都会包含校验和字段，用于检测数据是否损坏，如果检测到损坏，接收方直接丢弃数据包等待重传。
3. **确认应答**：接收方收到数据包之后会发送ACK确认收到的数据，ACK还包含收到数据包的序列号信息，发送方会根据是否收到ACK，以及ACK携带的序列号来判断下一步要做什么。
4. **重传机制**：重传机制有多种，比如超时重传、快速重传、SACK方法和Duplicate SACK方法。会在发送方确认接收方没有收到数据包之后重新发出数据包。
5. **流量控制**：`TCP`通过**滑动窗口**机制进行流量控制，确保接收方能够处理发送方的数据量。
6. **拥塞控制**：网络拥堵时，如果继续发送数据，可能导致数据包时延、丢失等，然后`TCP`会重传数据，导致网络负担更重，所以`TCP`通过**慢启动、拥塞避免、拥塞发生和快速恢复**等算法，来控制数据的发送速率，防止网络拥塞。

------

**重传机制**具体说明：

1. **超时重传**：数据包丢失和确认应答丢失两种情况会触发超时重传。发送方判断超时的依据是RTO，超时重传时间RTO应该要略大于报文往返RTT的值。RTO会随着网络波动而变化，会不断采样RTT和RTT的波动范围计算新的RTO。
2. **快速重传**：超时重传是时间驱动的，而快速重传是以数据驱动的。`TCP`发送数据包的顺序是严格的，如果一系列数据包中间有一个数据包丢失，接收方在返回ACK时就会携带该数据包的序列号，而忽略之后的数据包。发送方在收到三个带有同样序列号的ACK之后就判断该数据包丢失，直接重传数据包。
3. **SACK方法**：快速重传有一个缺点，接收方只会不断发送**第一个没有收到**的数据包的序列号，发送方并不清楚**只需要重传该数据包**还是该数据包之后全部重传。于是出现了SACK方法，选择性确认，会在TCP头部添加`SACK`，可以将已收到的数据的信息发送给发送方，之后发送方只重传丢失的数据。
4. **Duplicate SACK**：Duplicate SACK表示的是重复收到的数据包，通过ACK携带的数据包序列号与SACK进行区分，如果序列号在SACK范围前，那就是SACK，表示已收到，前面的包丢失，如果序列号在SACK范围后，那就是Duplicate SACK，表示前面的包重复收到。SACK和D-SACK合作的好处是可以知道具体是那个步骤除了错误，比如发送方数据包网络延迟，数据包丢失，或者接收方ACK丢失。

详细内容参考：

[4.2 TCP 重传、滑动窗口、流量控制、拥塞控制 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_feature.html#重传机制)

[『深入 TCP/IP 系列』一文搞懂 TCP 的可靠性随着前端技术的不断发展，越来越多的新事物、新技术出现在我们眼前，希 - 掘金](https://juejin.cn/post/6861491957534261255?searchId=20240712111538B2D895A393D1A22595FB#heading-6)

### Case2：

#### 题目：既然提到了拥塞控制，那你能说说拥塞控制是怎么是实现的吗

**答案：**

`TCP`拥塞控制可以在网络出现拥塞时动态调整数据传输的速率，防止网络过载。`TCP`的拥塞控制的实现如下：

为了使用拥塞控制算法，`TCP`发送方会维护**拥塞窗口**，他的值取决于网络的拥塞程度，并且动态变化。

- 原则是没有出现拥塞，窗口就增大，出现拥塞，窗口就减小。
- 判断拥塞出现的依据就是**是否发生超时重传**。

发送方会将拥塞窗口作为发送窗口，并维护一个慢开始门限`ssthresh`。

- 拥塞窗口小于门限，使用**慢开始**算法
- 大于门限，改用**拥塞避免**算法。

1. **慢开始（Slow Start）**：刚开始时，发送方的拥塞窗口为1，之后每接收到一个确认应答，窗口就会增加1，也就是拥塞窗口会随着发送数据的轮次指数级增长。有助于在网络刚开始传输时逐步增加速率。
2. **拥塞避免（Congestion Avoidance）**：拥塞窗口达到慢开始门限之后，改用拥塞避免算法，也就是拥塞窗口随着发送数据的轮次，每次只会增大1，是线性的增长。有助于控制发送速率。

在遇到拥塞情况时，发送方会把拥塞窗口置1，将慢开始门限设置为遇到拥塞时窗口大小的一半。这是**最初**的避免拥塞的算法，存在一定问题，比如报文在网络中丢失，实际上**并未发生拥塞**，但是发送方会进行超时重传，误认为网络拥塞，降低了**传输效率**。为了改善这些问题，有以下两个算法：

1. **快速重传（Fast Retransmit）**：快重传要求接收方收到数据后，**立即发送**确认应答，收到顺序不正确的报文也要立刻发送对已收到的报文的**重复确认**，而发送方收到连续三个重复确认之后，将相应的报文**立即重传**，不必等待超时后再重传。
2. **快速恢复（Fast Recovery）**：快速重传发生之后，进入快速恢复阶段。发送方不使用慢启动算法，直接将慢启动门限和窗口大小设置为当前窗口大小的一半；有的算法认为收到了三个重复确认，会设置为窗口的一半加三；也有算法会设置为当前窗口大小一半加上已确认的数据包数量。有助于快速从拥塞中恢复。

详细内容参考：

[计算机网络微课堂第069讲 TCP的拥塞控制（有字幕无背景音乐版）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1kJ41177io/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case3

#### 题目：TCP流量控制是怎么实现的

**答案：**

**流量控制**就是让发送方发送速率不要过快，让接收方来得及接收。利用**滑动窗口机制**就可以实施流量控制，动态调整数据传输速率。

1. **滑动窗口**：发送方会有一个滑动窗口，每个`TCP`报文段都包含一个窗口字段，发送方用这个字段说明当前滑动窗口的大小，也就是可以不用等待确认应答直接发送的数据大小。

2. **接收方窗口**：接收方会有一个接收方窗口，接收方会通过**确认应答**中的**窗口字段**告知发送方缓冲区中还有多少**可用空间**。

   发送方会根据接收方窗口大小**动态调整**自己的滑动窗口大小。这也就实现了流量控制的目标：接收方窗口增大时，发送方加速发送数据，接收方窗口减小，减缓发送数据，实现了动态调整，防止接收方缓冲区溢出。

3. **窗口关闭**：当接收方缓冲区用完时，会将窗口字段的值设为0，发送方收到后滑动窗口大小置0，也就是窗口关闭。直到接收方缓冲区有空间后，会向发送方发送设定窗口大小的报文，窗口重新打开。

4. **防止死锁**：那么如果接收方设定窗口大小的报文丢失了，可能会陷入死锁，为了防止这种情况呢，`TCP`设定了**零窗口探测报文**和**持续计时器**，同时`TCP`规定就算接收窗口为0，也必须接收**零窗口探测报文**、**确认报文**和带有**紧急数据**的报文。发送方的滑动窗口置0后，持续计时器就会启动，超时后发送零窗口探测报文，如果收到响应，窗口依旧为0，则**重启**持续计时器；如果零窗口探测报文丢失，或者响应报文丢失，会超时重传零窗口探测报文。

详细内容参考：

[计算机网络微课堂第068讲 TCP的流量控制（有字幕有背景音乐版）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1EJ411n7y7/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case4

#### 题目：UDP怎么实现可靠传输

**答案：**

`UDP`不属于连接型协议，无法保证可靠传输，所以不能指望在**传输层**实现可靠传输，需要在上面的**应用层**实现，也就是说传输的部分使用`UDP`，“可靠”的部分使用`QUIC`。

基于`QUIC`协议的报文主要结构从下到上是HTTP Message、HTTP3 Frame Header、**QUIC Frame Header**、**QUIC Packet Header**和UDP Header。其中比较重要的是**QUIC Frame Header**和**QUIC Packet Header**。

- **Packet Header**：细分为Long Packet Header和Short Packet Header，前者用来首次建立连接，后者用来常规传输数据。传输数据时，会用`Packet Number`作为每个报文的编号，他是**严格递增**的，也就是说有一个数据包丢失了，重传的数据包编号不会和原来的一致，编号会随发送顺序一直递增。

与`TCP`进行对比就可以明确为什么要这么做，使用`TCP`协议时，我们在一个数据包发送后，重传这个数据包，之后收到了确认应答，这时我们不清楚这个应答是来自于**原始数据包**还是**重传的包**，不能准确的计算RTT，而`Packet Number`严格递增就解决了这个问题。

此外，**单调递增**的设计让`QUIC`支持**乱序确认**，可以根据编号确认数据包是否丢失，如果丢失，重传的过程和发送新的包一致，发送方的滑动窗口只要有确认应答就可以向右滑动。这部分就实现了可靠传输中必要**的重传机制**。

但是还缺少一个重要功能，就是**接收方**如何在乱序接收的情况下按照**正确顺序**拼接报文。

- **Frame Header**：这部分要依赖Frame Header中的**Stream ID**和**Offset**。`HTTP/3.0`中利用Stream并发传输HTTP消息，用Stream ID区分不同的连接。Offset则类似于`TCP`中的序列号，保证数据的**顺序性和可靠性**。通过Stream ID + Offset来实现数据的**有序性**。

所以在数据包重传之后，虽然`Packet Number`不同，但是数据包中的Stream ID和Offset是一致的，可以通过他们确认乱序接收数据包的正确顺序。

详细内容参考：

[4.17 如何基于 UDP 协议实现可靠传输？ | 小林coding](https://xiaolincoding.com/network/3_tcp/quic.html#quic-是如何实现可靠传输的)

## Day8（卡哥没放Day7）

### Case1

#### 题目：TCP连接三次握手的过程，为什么是三次，可以是两次或者更多吗？

**答案：**

(1)三次握手的过程

1. **第一次握手**：客户端向服务器发送一个`SYN` （同步序列编号）报文，请求建立连接，客户端进入`SYN_SENT` 状态。报文中`TCP`头部的序列号字段会填充客户端随机初始化的**客户端序列号**。
2. **第二次握手**：一开始服务器处于`Listen`的状态，收到`SYN` 报文后，如果同意建立连接，则会发送一个`SYN-ACK` （同步确认）报文作为响应，同时进入`SYN_RCVD` 状态。报文中`TCP`头部的序列号会填充服务器随机初始化的**服务器序列号**，但是确认应答号会填充收到的**客户端序列号加一**。
3. **第三次握手**：客户端收到服务器的`SYN-ACK` 报文后，会发送一个`ACK` （确认）报文作为最终响应，报文中的确认应答号则填入**服务器序列号加一**，这样双方的序列号就**同步**了。报文发出后客户端进入`ESTABLISHED` 状态，服务器收到`ACK`后也进入`ESTABLISHED`状态。

(2)为什么需要三次握手

1. 通过三次握手，可以确认双方的**接收和发送**能力：

   第一次握手确认了客户端到服务器的通道是开放的；

   第二次握手确认了服务器到客户端的通道是开放的，以及服务器有接收的能力；

   第三次握手则确认了客户端有接收的能力。

2. 避免重复**历史连接**：

   如果只握手两次，假如客户端在发出一个`SYN`报文之后宕机了，重启之后又发送了一个`SYN`报文，那么服务器会创立**一条不应该存在的连接**，而且客户端并不清楚这件事情的发生。

3. 初始化**序列号**

   `TCP`连接为了实现可靠传输，需要通信双方维护两个**序列号**，而双方序列号的同步需要每方至少**发送和接收各一次**，所以握手次数最少是三，更多次则没有必要，过程可以被优化为三次。

详细内容参考：

[一条视频讲清楚TCP协议与UDP协议-什么是三次握手与四次挥手_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1kV411j7hA/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

[4.1 TCP 三次握手与四次挥手面试题 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#tcp-三次握手过程是怎样的)

### Case2

#### 题目：TCP连接四次挥手的过程，为什么是四次？

**答案：**

（1）四次挥手的过程

1. **第一次挥手**：客户端发送一个`FIN`报文给服务器，表示自己要断开连接，报文中会指定之前数据传输过程中前一个服务器报文的**确认应答号**作为序列号。然后，客户端进入`FIN_WAIT_1 `状态。
2. **第二次挥手**：服务器收到`FIN`报文后，回复`ACK`报文给客户端，把客户端的序列号值`+1`，作为ACK报文的**确认应答号**。然后，服务器进入`CLOSE_WAIT`状态，客户端收到报文后进入`FIN_WAIT_2`状态。
3. **第三次挥手**：服务器传输完所有数据后，需要断开连接时，发送`FIN`报文给客户端，且指定前一个客户端报文的**确认应答号**作为序列号，随后服务端进入`LAST_ACK`状态。
4. **第四次挥手**：客户端收到`FIN`报文后，发出`ACK`报文进行应答，并把服务器的序列号值`+1`作为**确认应答号**。此时客户端进入`TIME_WAIT`状态。服务器在收到客户端的`ACK`报文后进入`CLOSE` 状态。如果客户端等待2个`MSL`（报文最大生存时间）没有收到回复，才关闭连接。如果报文丢失，服务器会在2个`MSL`内再次发送`FIN`报文。

（2）为什么需要四次挥手

`TCP`是全双工通信，可以双向传输数据。四次挥手可以拆分为两组由不同通信方发起的连接释放。

1. 第一次发送`FIN`报文，表示自己不再发送数据，但还可以接收数据。收到`ACK`表示另一方已知晓。
2. 第二次由另一方发送`FIN`报文，表示双方都没有数据需要传输了，那么确认后就可以关闭连接。

因此两次挥手可以释放一端到另一端的`TCP`连接，完全释放连接一共需要四次挥手。

只有通过四次挥手，才可以确保双方都能接收到对方的最后一个数据段的确认，主动关闭方在发送完最后一个`ACK`后进入`TIME_WAIT` 状态，这是为了确保被动关闭方接收到最终的`ACK` 。

而如果使用三次挥手，就会有一方无法收到`ACK`报文或者需要合并`FIN`和`ACK`报文。

详细内容参考：

[4.22 TCP 四次挥手，可以变成三次吗？ | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_three_fin.html#tcp-四次挥手)

[TCP 序列号和确认号是如何变化的？ - 知乎](https://zhuanlan.zhihu.com/p/577528304)

[一条视频讲清楚TCP协议与UDP协议-什么是三次握手与四次挥手_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1kV411j7hA/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case3

#### 题目：HTTP的Keep-Alive是什么？TCP的Keepalive和HTTP的Keep-Alive是一个东西吗？

**答案：**

1. `HTTP` 的 `Keep-Alive`，是由应用层实现的，称为`HTTP`长连接。

   `HTTP`请求需要经历这样的过程：建立 `TCP`连接 -> `HTTP`请求资源 -> 响应资源 -> 释放连接，这就是`HTTP`短连接，但是这样每次建立连接都只能请求一次资源，而且每次都需要三次握手四次挥手，开销很大。
   所以`HTTP`的 `Keep-Alive`实现了使用同一个 TCP 连接来发送和接收多个`HTTP`请求/应答，避免了连接建立和释放的开销，这就是**HTTP 长连接**，`HTTP`还基于长连接实现了`HTTP`流水线等功能。长连接通过设置`HTTP`首部字段`Connection: keep-alive`来实现，在`HTTP/1.1`后是默认开启的。
   为了防止浪费资源，web服务软件会**启动定时器**，一段时间没有新的请求就释放连接。

2. `TCP` 的 `Keepalive`，是由`TCP`层（内核态）实现的，称为 **`TCP`保活机制**，是一种用于在 `TCP`连接上检测空闲连接状态的机制。

   当`TCP`连接建立后，如果一段时间内没有任何数据传输，`TCP Keepalive`会发送探测包来检查连接是否仍然有效。如果对端主机宕机（不是进程崩溃，进程崩溃是可感知的，宕机不可感知），或者其他原因**报文不可达**，在经过一定次数的保活探测之后，`TCP`会报告`TCP`连接死亡。

详细内容参考：

[4.15 TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？ | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_http_keepalive.html#http-的-keep-alive)

[18-滴滴面试题-HTTP长连接和短连接？(http keep_alive tcp keep_alive 心跳检测机制,内核源码分析tcpkeepalive)_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1XV4y1Y7ig/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

## Day9

### Case1

#### 题目：DNS查询过程

**答案：**

`DNS` 用来将主机名和域名转换为IP地址，其查询过程一般通过以下步骤：

1. **本地`DNS`缓存检查**：首先查询本地`DNS`缓存，本地缓存的查询顺序是：本地`host`文件，操作系统级别的`DNS`缓存，浏览器缓存。如果本地缓存中有对应的IP地址，则直接返回结果。
2. 如果本地缓存中没有，则会向**本地的`DNS`服务器**（通常由你的互联网服务提供商（ISP）提供， 比如中国移动）发送一个`DNS`查询请求。
   以上部分就是`DNS`查询的**递归**过程。
3. 如果本地`DNS`服务器有该域名的IP地址，就会直接返回，如果没有缓存该域名的解析记录，它会向**根`DNS`服务器**发出查询请求。根`DNS`服务器并不负责解析域名，但它能告诉本地`DNS`服务器应该向哪个顶级域（.com/.net/.org）的`DNS`服务器继续查询。
4. 本地`DNS`服务器接着向指定的**顶级域`DNS`服务器**发出查询请求。顶级域`DNS`服务器也不负责具体的域名解析，但它能告诉本地`DNS`服务器应该前往哪个权威`DNS`服务器查询下一步的信息。
5. 本地`DNS`服务器最后向**权威`DNS`服务器**发送查询请求。 权威`DNS`服务器是负责存储特定域名和IP地址映射的服务器，收到查询请求时，它会查找`"example.com"`域名对应的IP地址，并将结果返回给本地`DNS`服务器。
6. 本地`DNS`服务器将收到的IP地址返回给浏览器，并且还会将域名解析结果缓存在本地，以便下次访问时更快地响应。
   以上就是`DNS`查询的**迭代**过程。
7. **浏览器发起连接：** 本地`DNS`服务器已经将IP地址返回给计算机，浏览器可以使用该IP地址与目标服务器建立连接，开始获取网页内容。

详细内容参考：

[DNS域名解析过程_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1uL4y1B7aE/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

[2.2 键入网址到网页显示，期间发生了什么？ | 小林coding](https://xiaolincoding.com/network/1_base/what_happen_url.html#真实地址查询-dns)

### Case2

#### 题目：CDN是什么，有什么作用？

**答案：**

CDN全称是**内容分发网络**，是一种分布式网络服务，将内容存储于分布在不同地理位置的服务器上，使用户可以从距离较近的服务器获取所需的内容，从而加速互联网上的内容传输。

CDN在整个DNS查询中的参与过程如下：

1. 本地DNS缓存不存在域名对应的IP地址，就会进行DNS迭代查询。
2. 当迭代查询到**权威DNS服务器**时，不使用CDN会返回源服务器的IP地址。使用CDN后，权威DNS服务器会有一个别名指向**CDN服务器的域名**，权威DNS服务器解析后得到**CDN负载平衡器**的IP地址，发给本地DNS服务器。
3. 本地DNS服务器会继续要求**CDN负载平衡器**继续解析，负载平衡器则根据用户的IP地址、ISP、请求内容，服务器的负载情况等选择一个CDN边缘服务器返回给本地DNS服务器。

CDN主要实现了三个功能：

- **就近访问**：CDN 在全球范围内部署了多个服务器节点，用户的请求会被路由到距离最近的 CDN 节点。
- **内容缓存**：CDN 节点会缓存**静态资源**，如图片、表格、脚本等。当用户请求访问这些资源时。如果有缓存，CDN 节点会直接返回缓存的资源，如果没有缓存所需资源，它会从源服务器（原始服务器）获取资源，并将资源缓存到节点中，以便以后的请求。同时也会提供一些**动态资源**，比如本地的时间以及一些便于计算的资源。
- **负载均衡**：即使某些节点出现问题或者负载过大，用户请求可以被重定向到其他的节点。

详细内容参考：

[什么是CDN？CDN能为我们做什么？我们为什么要了解他？_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1jS4y197zi/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

[面试官：CDN 是怎么工作的？](https://mp.weixin.qq.com/s/6KC6uUofPmOM4Ylm-ji1kg)

### Case3

#### 题目：Cookie和Session是什么？有什么区别？

**答案：**

(1) Cookie和Session是什么？

`Cookie`和 `Session`在Web开发中都用于管理用户的状态和身份, `Cookie`通过在**客户端**记录信息确定用户身份，`Session`通过在**服务端**记录信息确定用户身份。

1. Cookie

   - 通常，服务器会将一个或多个` Cookie` 发送到用户浏览器，然后浏览器将这些 `Cookie` 存储在本地。
   - 客户端会在请求的头部携带`Cookie`，服务器可以通过分析`Cookie`得到客户端相关信息，从而动态生成与该客户端相对应的内容。

2. Session

   客户端浏览器访问服务器的时候，服务器把客户端信息存储在服务器就是`Session`。Session 主要用于维护用户登录状态、存储用户的临时数据和上下文信息等。服务器为每个用户分配一个唯一的`Session ID`，通常存储在`Cookie`中。

（2） Cookie和Session的区别？

- 存储位置：`Cookie`数据存储在用户的浏览器中，而`Session`数据存储在服务器上。
- 数据容量：`Cookie`存储容量较小，一般限制在4KB左右。`Session`存储容量较大，通常没有固定限制，取决于服务器的配置和资源。
- 安全性：由于`Cookie`存储在用户浏览器中，容易受到XSS（跨站脚本攻击）威胁。`Session`数据存储在服务器上，相对来说更安全，但是仍然需要防范`Session`劫持等。
- 生命周期：`Cookie`可以设置过期时间，也可以设置为会话`Cookie`，在浏览器关闭时自动删除。`Session` 默认会在浏览器关闭时结束，但是服务器也可以设置**超时时间**，未活动时间超时才会失效。
- 传输方式：`Cookie` 在每次 `HTTP` 请求中都会被自动发送到服务器，而 `Session ID` 通常通过` Cookie` 或 URL 参数传递。

详细内容参考：

[同程旅行 Java 面试 | 小林coding](https://xiaolincoding.com/backend_interview/internet_medium/tongchenglvxing.html#cookie和session之间区别-介绍一下)

[Cookie、Session、Token究竟区别在哪？如何进行身份认证，保持用户登录状态？_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1ob4y1Y7Ep/?share_source=copy_web&vd_source=db4b8256b37979f4e7f296b129aaaf87)

## Day10

### Case1

#### 题目：进程和线程之间有什么区别

**答案：**

**进程是资源分配基本单位。线程是程序执行的最小单位、调度的基本单位**。一个进程至少有一个线程，可以有多个线程。

两者的区别主要在以下几个方面：

1. **资源开销**：

   - **进程**：每个进程都有一个完整的资源平台，有独立的内存空间，创建和销毁进程的开销较大。
   - **线程**：线程只独享必不可少的资源，比如寄存器和栈，会和**其他线程**共享**进程**的内存空间，创建和销毁线程的开销较小。

2. **上下文切换**：操作系统的任务调度，实际上的**调度对象是线程**，进程只是给线程提供了虚拟内存、全局变量等资源。

   - 所以当进程只有一个线程时，可以认为进程就等于线程；
   - 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在**进程内**上下文切换时是不需要修改的。

   所以在**线程的上下文切换**时：

   - 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
   - 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据

   总体来看**线程**的上下文切换比**进程**的上下文切换开销要小很多。

3. **通信与同步**：

   - **进程**：由于进程间相互隔离，进程之间的通信需要使用一些特殊机制，如管道、消息队列、共享内存等。
   - **线程**：由于线程共享相同的内存空间，它们之间可以直接访问共享数据，线程间通信更加方便。

4. **安全性**：

   - **进程**：由于进程间相互隔离，一个进程的崩溃不会直接影响其他进程的稳定性。
   - **线程**：由于线程共享相同的内存空间，一个线程的错误可能会影响整个进程的稳定性。

详细内容参考：

[5.1 进程、线程基础知识 | 小林coding](https://xiaolincoding.com/os/4_process/process_base.html#线程与进程的比较)

[【操作系统】进程和线程的区别_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Wr4y1P7Yr/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case2

#### 题目：并行和并发有什么区别

**答案：**

- 并行是在**同一时刻**执行多个任务。

  并行的关键是这些任务是同时进行的，举例来说，现在有一个多核的CPU，同时有小于核心数量的子任务个数，那么每个任务都会在不同的核上执行，过程中**没有线程调度**。在一个并行系统中，多个核心可以同时处理相互独立的子任务，从而加速整体任务的完成。

- 并发是在**相同的时间段**内执行多个任务。

  任务之间并不是同时进行的，多数情况下**交替执行**，通过调度实现，比如通过**时间片轮转**或者**事件驱动**的方式。举例来说，在一个多核CPU上，现在任务数量非常多，那么每个核心都会有多个子任务需要完成，为了使每个子任务保持执行，就是采用并发来交替执行各个任务。

详细内容参考：

[一个视频告诉你“并发、并行、异步、同步”的区别_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV17V411e7Ua/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case3

#### 题目：解释一下用户态和内核态，什么场景下，会发生内核态和用户态的切换?

**答案：**

**一、**用户态和内核态的区别

用户态和内核态是操作系统为了保护系统资源和实现权限控制而设计的两种不同的**CPU运行级别**，可以**控制进程或程序对计算机硬件资源的访问权限和操作范围。**

- **用户态**：在用户态下，进程或程序只能执行部分指令集，无法直接访问硬件资源，操作权限较低，主要用于运行用户程序。
- **内核态**：内核态是操作系统的**特权**级别，允许进程或程序执行所有的指令和访问所有的硬件资源。拥有更高的操作权限，主要用于操作系统内核的运行。
  内核态的底层操作主要包括：**内存管理、进程管理、设备驱动程序控制、系统调用**等。这些操作涉及操作系统的核心功能，需要较高的权限。

**二、**在什么场景下，会发生内核态和用户态的切换

- 系统调用：当用户程序需要请求操作系统提供的服务时，会通过**系统调用**进入内核态。
- 异常：当程序执行过程中**出现错误或异常情况**时，CPU会自动切换到内核态，以便操作系统能够处理这些异常。
- 中断：外部设备（如键盘、鼠标、磁盘等）产生的**中断信号**会使CPU从用户态切换到内核态。操作系统会执行相应的中断处理程序，然后再将CPU切换回用户态。

**三、分为内核态和用户态的原因主要有以下几点：**

- 安全性：通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源的破坏。
- 稳定性：用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃的风险。
- 隔离性：内核态和用户态的划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统的模块化和维护。

内核态和用户态的划分有助于保证操作系统的安全性、稳定性和易维护性。

详细内容参考：

[操作系统面试题 | 小林coding](https://xiaolincoding.com/interview/os.html#用户态和内核态的区别)

## Day11

### Case1

#### 题目：进程调度算法你了解多少

**答案：**

进程调度算法一般指的是**单核CPU**系统中的调度算法。调度的进程大致可以分为两类，一类是**计算密集型**，一类是**I/O密集型**，前者占用CPU时间较长，后者更多时间用于I/O通信，占用CPU时间较短。

- **先来先服务**：**非抢占式**的调度算法，按照请求的顺序进行调度。 这种调度方式简单，但是可能导致长作业阻塞短作业。
- **最短作业优先**：**非抢占式**的调度算法，系统会**估计**作业所需要的运行时间，优先调用短作业。 但是如果一直有短作业到来，会造成长作业“饥饿”现象。
- **最短剩余时间优先**：基于最短作业优先改进，按**剩余运行时间**判断优先级。当一个新的作业到达时，将其运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。也有可能导致长作业“饥饿”现象。
- **高响应比优先调度**：高响应比优先的主要目的是**权衡短作业和长作业**，响应比的计算公式是**(等待时间 + 剩余运行时间) / 剩余运行时间**，算法会根据公式得到的优先级来调度。
- **时间片轮转调度**：对每个进程**一视同仁**，为每个进程分配一个时间片，进程轮流执行，时间片用完后切换到下一个进程。注意时间片太短会导致过多上下文切换，降低效率，过长会导致短作业进程等待时间变长。
- **优先级调度**：进程的优先级可以分为**静态优先级**和**动态优先级**，前者在进程创建时确定，后者会根据进程情况**动态调整**，比如运行时间增加会降低优先级，等待时间增加会升高优先级。算法会按优先级进行调度，处理方式可以分为抢占式和非抢占式。
- **多级反馈队列**：结合了**时间片轮转调度**算法和**优先级调度**算法。 将进程分为不同的优先级队列，每个队列内部有自己的调度算法，各个队列有自己的时间片用于执行进程。一个进程在当前队列没有执行完，会进入下一个优先级的队列继续等待。

详细内容参考：

[5.1 进程、线程基础知识 | 小林coding](https://xiaolincoding.com/os/4_process/process_base.html#调度算法)

[【操作系统】CPU调度算法_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Kz4y117gZ/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case2

#### 题目：进程间有哪些通信方式

**答案：**

1. **管道**：所有管道的数据传输都是**单向**的，而且遵循**先进先出**的原则。

   - **匿名**管道：Linux命令中有一个`|`，它就是一个管道，作用是将左侧命令的输出作为右侧命令的输入，这种管道没有名字，所以被称为**匿名管道**，会随着进程结束销毁，且通信范围是存在**父子关系的进程**。
   - **命名**管道：如果在创建管道的时候指定名字，那就是命名管道，与管道类似，但是通信范围可以是**两个不相关的进程**。

   管道的优势在于**简单**，但是**通信效率很低**，不适合频繁交换数据。

2. **消息队列**：消息队列是保存在内核中的**消息链表**，发送方将输入放入对应队列后就可以正常返回了，在接收方读取后，会从队列中删除这个消息体。因为队列保存在**内核**中，所以过程中会发生**用户态和内核态之间**拷贝数据。
   消息队列的优点是通信效率相对管道高，缺点在于通信不及时，也不适合大数据量的传输。

3. **共享内存**：消息队列中，会发生用户态和内核态之间消息拷贝的情况，共享内存解决了这一问题。共享内存的机制是**拿出一块虚拟地址空间，映射到相同的物理内存中**，多个进程都可以访问。由于不需要数据拷贝，共享内存是**最快**的进程通信方式。

4. **信号量**：共享内存的通信方式会带来新的问题，如果多个进程**同时修改**同一个共享内存，先写的内容可能会被覆盖。为了防止进程竞争资源，信号量实现了一种锁机制，让**任意时刻某个资源只能被一个进程访问**。信号量表示资源的数量，控制方式有两种原子操作：

   - **P操作**：将信号量减一，表示占用一个资源，资源量不足时会使进程阻塞等待。
   - **V操作**：将信号量加一，表示释放一个资源。

   P操作和V操作必须成对出现。

5. **信号**：前面几种进程间通信，都是常规状态下的工作模式，对于**异常情况**下的工作模式，需要用**信号**的方式来通知进程。Linux系统中提供了几十种信号，分别代表不同的意义。
   信号是进程间通信机制中唯一一种**异步通信机制**，可以在任何时候发送信号给某一进程。对于信号的处理方式有以下几种：

   1. **执行默认操作**：Linux对每种信号都规定了默认操作。
   2. **捕捉信号**：可以定义一个信号处理函数，接收信号后执行函数。
   3. **忽略信号**：其中`SIGKILL`和`SEGSTOP`是无法捕捉和忽略的。

6. **Socket**：以上的机制都是在同一台主机上通信，如果需要**跨网络与不同主机的进程通信**，需要使用Socket，要绑定**IP地址和端口**。如果用于本地通信，则需要绑定**本地文件**。

详细内容参考：

[5.2 进程间有哪些通信方式？ | 小林coding](https://xiaolincoding.com/os/4_process/process_commu.html#管道)

[大厂面试笔试题31丨进程间通信方式_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1tv411p7WX/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

[『面试问答』：进程间通信的方式有哪些？_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1oX4y177y7/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)

### Case3

#### 题目：解释一下进程同步和互斥，以及如何实现进程同步和互斥

**答案：**

进程**同步**指的是多个并发进程在一些关键点上可能需要互相等待或者互通消息，以确保他们**按照一定顺序或者时间间隔执行**。

进程**互斥**指的是，在多个进程需要访问同一个资源时，他们之间是**竞争关系**，可能在操作同一个变量时发生上下文切换等导致结果错误。我们把访问资源的这一段代码称为**临界区**，互斥就是保证临界区每次**最多出现一个**进程。

解决进程同步和互斥的问题有很多种方法，其中一种常见的方法是使用**信号量和 PV 操作**。信号量表示系统中某种资源的数量或者状态。PV 操作是用于操作信号量的**原子操作**。

- **P操作**：相当于“占用”信号量，如果资源可用，就减少信号量计数，然后使用资源。
- **V操作**：相当于“归还”资源，增加信号量的计数，并可能唤醒等待的进程。

除此之外，下面的方法也可以解决进程同步和互斥问题：

- **临界区**：将可能引发互斥问题的代码段称为临界区，里面包含了需要互斥访问的资源。进入这个区域前需要先获取锁，退出临界区后释放该锁。这确保同一时间只有一个进程可以进入临界区。
- **互斥锁（Mutex）**：将每个共享资源都关联一个互斥锁，进程在访问该资源前需要先获取互斥锁，使用完后释放锁。只有获得锁的进程才能访问共享资源。
- **条件变量**：条件变量用于在进程之间传递信息，通常与互斥锁一起使用。互斥锁只有锁定和非锁定两种状态，而条件变量可以**允许线程阻塞和等待其他线程的消息**，弥补了互斥锁的不足。

详细内容参考：

[5.3 多线程冲突了怎么办？ | 小林coding](https://xiaolincoding.com/os/4_process/multithread_sync.html#竞争与协作)

## Day12

### Case1

#### 题目：什么是死锁，如何避免死锁？

**答案：**

死锁是系统的多个进程在执行过程中，因争夺资源而造成的一种**僵局**。当每个进程都**持有一定的资源**并**等待其他进程释放它们所需的资源**时，如果所有进程都不释放资源，就导致了**死锁**。

死锁只有同时满足以下四个条件才会发生：

- **互斥条件**：多个进程不能同时使用同一个资源。
- **持有并等待条件**：一个进程因为请求资源而被阻塞的时候，不会释放自己持有的资源。
- **不可剥夺条件**：一个进程持有的资源只能由自己主动释放，不能被强制性的剥夺。
- **环路等待条件**：多个进程获取资源的顺序构成了环形链，每个进程都在等待下一个进程所占有的资源。

避免死锁有以下几种方法：

1. 避免死锁：**避免死锁的常见方法就是破坏其中一个条件**。最常见并且可行的就是**使用资源有序分配法破坏环路等待条件**。也就是说如果有多个进程需要获取相同的几个资源，他们获取这几个资源的**顺序必须是一致**的，就可以打破死锁。
2. 检测死锁：通过检测系统中的资源分配情况来判断是否存在死锁。比如，可以使用**资源分配图**或**银行家算法**进行检测。
3. 解除死锁：一旦检测到死锁存在，可以采取一些措施来解除死锁。比如，可以通过抢占资源、终止某些进程或进行资源回收等方式来解除死锁。

详细内容参考：

[5.4 怎么避免死锁？ | 小林coding](https://xiaolincoding.com/os/4_process/deadlock.html#死锁的概念)

### Case2

#### 题目：介绍一下几种典型的锁

**答案：**

最基本的两种锁是**互斥锁和自旋锁**，加锁的目的在于保证共享资源在任意时间里，只有一个线程访问，可以防止数据错误。如果当前资源有一个线程加锁之后，其他线程加锁就会失败，互斥锁和自旋锁对于**加锁失败**的处理方式是不同的。

- **互斥锁**：互斥锁加锁失败之后，线程会**释放CPU**进入阻塞状态。
- **自旋锁**：自旋锁加锁失败后，线程会**忙等待**，即线程在尝试获取锁时会**不断轮询**，直到拿到锁。

互斥锁会增加两次上下文切换的成本，如果被锁定的代码**执行时间短**，优先使用自旋锁。

其他的锁都是基于上面这两个锁的

- **读写锁**：分为**读锁**和**写锁**两部分，用于明确区分读和写两种场景。当写锁没有被线程持有时，多个线程可以并发地持有读锁，一旦**写锁**被持有，获取**读锁和写锁**的操作都会被阻塞。提高了共享资源的访问效率，适用于**读多写少**的场景。
  上述情况容易出现读线程饥饿，所以有一种**公平读写锁**，读线程和写线程都按照先进先出的方式加锁。
- **悲观锁**：之前的互斥锁、自旋锁、读写锁都是悲观锁，他认为多线程同时修改共享资源的概率比较高，容易出现冲突，所以访问共享资源前必须先上锁。
- **乐观锁**：选择**先修改**共享资源，再验证这段时间有没有**其他线程在修改**资源，如果没有，操作完成，如果有就放弃本次操作。乐观锁全程没有加锁，可以叫无锁编程，只有在**冲突概率低**，并且**加锁成本高**时使用。

详细内容参考：

[5.5 什么是悲观锁、乐观锁？ | 小林coding](https://xiaolincoding.com/os/4_process/pessim_and_optimi_lock.html#互斥锁与自旋锁)

### Case3

#### 题目：讲一讲你理解的虚拟内存

**答案：**

随着计算机的发展，我们运行程序时需要加载的数据是越来越大的，**内存**中逐渐**放不下**这些数据了，那么我们的选择就是将部分数据存放在**硬盘**中，需要的时候加载到内存里，同样的，内存中有部分用不到的数据，也会被移到硬盘中。

这个过程中，为了不影响程序的运行，我们提出了**虚拟内存地址**和**物理内存地址**两个概念，前者是程序所使用的内存地址，后者是硬件中实际存在的地址，两者之间的映射关系使用**内存管理单元（MMU）**来管理，程序运行时会分配一个**连续的虚拟地址空间**，让程序认为他有**足够的空间**来运行。

虚拟内存的**功能**：

- **内存扩展**：虚拟内存使得每个程序都可以使用**比实际可用内存更大**的空间。
- **内存隔离**：虚拟内存还提供了进程之间的内存隔离，一个进程无法直接访问另一个进程的内存。
- **物理内存管理**：也就是前面提到的，虚拟内存允许操作系统**动态地**将数据和程序的部分加载到物理内存中，当物理内存**不足**时，操作系统可以将不常用的数据或程序暂时移到硬盘上，从而释放内存。
- **内存映射文件**：虚拟内存可以将文件映射到内存中，可以让文件的读取和写入像访问内存一样高效。

上述功能中的**物理内存管理**的实现主要依靠以下几种方法：

- **内存分段**：分段机制下的地址由**段选择因子**和**段内偏移量**组成。前者用作段表的索引，找到**段的基地址和界限**，后者用于定位具体地址。
- **内存分页**：分页机制把整个虚拟和物理内存空间分割成多个固定大小的页，使用**内存管理单元（MMU）**来管理两者之间的映射关系。还引申出了**多级页表**等形式。
- **段页式管理**：结合了上述两种方法，地址由**段号**、**段内页号**和**页内位移**三部分组成。

详细内容参考：

[4.1 为什么要有虚拟内存？ | 小林coding](https://xiaolincoding.com/os/3_memory/vmem.html#虚拟内存)

[【操作系统】内存管理——虚拟内存_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV18v411a7Vk/?share_source=copy_web&vd_source=9bb0aa9c2c3cc1b12ca6f343a55b4e80)









